import os
import json
import time
import logging
from pdf_processor import prepare_cv_text
from postprocess import postprocess_filled_cv, fix_open_date_ranges, safe_parse_if_str
from chatgpt_client import (
    gpt_extract_cv_without_projects,
    gpt_extract_projects_text,
    gpt_structurize_projects_from_text,
)
import ast

# === Pfade ===
INPUT_PDF = "data_input/CV Manuel Wolfsgruber.pdf"
RAW_GPT_JSON = "data_output/raw_gpt.json"
OUTPUT_JSON = "data_output/result_Manuel_1.json"

# === Hauptpipeline ===
def main():
    start_time = time.time()
    logging.basicConfig(level=logging.INFO, format="%(message)s")
    logging.info("üöÄ Starte vollst√§ndige CV-Pipeline (PDF ‚Üí GPT ‚Üí JSON)...")

    # 1Ô∏è‚É£ Textvorbereitung (–≤–∫–ª—é—á–∞—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –±–ª–æ–∫–æ–≤)
    prepared_text, raw_text = prepare_cv_text(INPUT_PDF)
    logging.info("üìÑ Text erfolgreich extrahiert und normalisiert (inkl. Projektdaten & Datumszeilen).")

    # üìÅ Sicherstellen, dass der Output-Ordner existiert
    os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)

    # üîπ Optional: –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç (Schema-1-Text)
    schema1_text_path = os.path.join(os.path.dirname(OUTPUT_JSON), "schema1_text.txt")
    with open(schema1_text_path, "w", encoding="utf-8") as f:
        f.write(prepared_text)

    # 2Ô∏è‚É£ GPT: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (TEXT 2)
    logging.info("üß† GPT-Schritt 1b: Extrahiere reinen Projekttext...")
    projects_text_result = gpt_extract_projects_text(raw_text)
    if not projects_text_result.get("success"):
        logging.error("‚ùå GPT (Projekt-Text) hat keine g√ºltige Antwort geliefert.")
        return

    projects_text = projects_text_result.get("text", "") or ""
    projects_raw_txt_path = os.path.join(os.path.dirname(OUTPUT_JSON), "projects_raw.txt")
    with open(projects_raw_txt_path, "w", encoding="utf-8") as f:
        f.write(projects_text)

    # 3Ô∏è‚É£ GPT-Schritt 2: CV ohne Projekte (Schema 1 aus TEXT 1)
    logging.info("üß† GPT-Schritt 2: Extrahiere CV ohne Projekte...")
    base_result = gpt_extract_cv_without_projects(raw_text)
    if not base_result.get("success"):
        logging.error("‚ùå GPT (Schema ohne Projekte) hat keine g√ºltige Antwort geliefert.")
        return
    base_cv = base_result.get("json", {}) or {}

    # üîπ –°–æ—Ö—Ä–∞–Ω—è–µ–º Schema 1 –∫–∞–∫ JSON
    schema1_json_path = os.path.join(os.path.dirname(OUTPUT_JSON), "schema1.json")
    with open(schema1_json_path, "w", encoding="utf-8") as f:
        json.dump(base_cv, f, indent=2, ensure_ascii=False)

    # 4Ô∏è‚É£ GPT-Schritt 3: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏–∑ TEXT 2 –≤ —Ü–µ–ª–µ–≤—É—é —Å—Ö–µ–º—É
    logging.info("üß† GPT-Schritt 3: Strukturiere Projekte aus projects_raw.txt...")
    projects_struct_result = gpt_structurize_projects_from_text(projects_text)
    if not projects_struct_result.get("success"):
        logging.error("‚ùå GPT (Projekt-Structurierung) hat keine g√ºltige Antwort geliefert.")
        return

    projects_payload = projects_struct_result.get("json", {}) or {}
    projects_experience = projects_payload.get("projects_experience", [])

    # üîπ –°–æ—Ö—Ä–∞–Ω—è–µ–º Schema 2 (—Ç–æ–ª—å–∫–æ –ø—Ä–æ–µ–∫—Ç—ã) –∫–∞–∫ JSON
    projects_schema_path = os.path.join(os.path.dirname(OUTPUT_JSON), "projects_schema.json")
    with open(projects_schema_path, "w", encoding="utf-8") as f:
        json.dump(projects_payload, f, indent=2, ensure_ascii=False)

    # 5Ô∏è‚É£ Merge: Schema 1 + Schema 2 (–ø—Ä–æ–µ–∫—Ç—ã)
    filled_json = base_cv
    filled_json["projects_experience"] = projects_experience
    raw_gpt_response = projects_struct_result.get("raw_response", "")

    # 4Ô∏è‚É£ Passenden raw_text w√§hlen
    raw_for_postprocess = raw_text

    # 5Ô∏è‚É£ Rohdaten speichern
    os.makedirs(os.path.dirname(RAW_GPT_JSON), exist_ok=True)
    with open(RAW_GPT_JSON, "w", encoding="utf-8") as f:
        json.dump(filled_json, f, indent=2, ensure_ascii=False)
    logging.info(f"üíæ Rohdaten von GPT gespeichert unter: {RAW_GPT_JSON}")

    # 6Ô∏è‚É£ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤
    for key in ["projects_experience", "skills_overview", "languages"]:
        filled_json[key] = safe_parse_if_str(filled_json.get(key))
        # –µ—Å–ª–∏ –≤—Å–µ –µ—â–µ —Å—Ç—Ä–æ–∫–∞ ‚Äî –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ ast.literal_eval
        if isinstance(filled_json.get(key), str):
            try:
                filled_json[key] = ast.literal_eval(filled_json[key])
            except Exception:
                filled_json[key] = []

    # 7Ô∏è‚É£ Nachbearbeitung (–ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥)
    logging.info("üß© F√ºhre Nachbearbeitung durch...")
    filled_json = postprocess_filled_cv(filled_json, raw_for_postprocess)

    # üß† –ü–æ–≤—Ç–æ—Ä–Ω–∞—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    for key in ["projects_experience", "skills_overview", "languages"]:
        filled_json[key] = safe_parse_if_str(filled_json.get(key))
        if isinstance(filled_json.get(key), str):
            try:
                filled_json[key] = ast.literal_eval(filled_json[key])
            except Exception:
                filled_json[key] = []

    # 8Ô∏è‚É£ –ê–≤—Ç–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–æ–ª–µ–π –∏ –¥–∞—Ç –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –≤ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥.
    # –ó–¥–µ—Å—å –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –ù–ï –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º —Ä–æ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Consultant")
    # –∏ –ù–ï –∫–æ–ø–∏—Ä—É–µ–º duration –∏–∑ –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.
    # –í—Å–µ —Ç–∞–∫–∏–µ –¥–æ–≥–∞–¥–∫–∏ —Ç–µ–ø–µ—Ä—å –¥–µ–ª–∞–µ—Ç (–∏–ª–∏ –ù–ï –¥–µ–ª–∞–µ—Ç) —Ç–æ–ª—å–∫–æ –ø–æ—Å—Ç–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    # –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞.

    # üëá Auf offene Datumsbereiche pr√ºfen (z. B. ‚Äûbis heute‚Äú)
    filled_json = fix_open_date_ranges(filled_json)

    # 9Ô∏è‚É£ Metadaten hinzuf√ºgen
    filled_json["_meta"] = {
        "source_pdf": INPUT_PDF,
        "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "processing_time_sec": round(time.time() - start_time, 2),
        "model": "gpt-5-mini",
        "gpt_mode": "two-step-projects"  # –∏–ª–∏ –ª—é–±–æ–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    }

    # üîü Finale Daten speichern
    os.makedirs(os.path.dirname(OUTPUT_JSON), exist_ok=True)
    with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
        json.dump(filled_json, f, indent=2, ensure_ascii=False)

    # ‚ÑπÔ∏è Logging summary
    logging.info(f"‚úÖ Endergebnis gespeichert unter: {OUTPUT_JSON}")
    logging.info(f"üìä Projekte: {len(filled_json.get('projects_experience', []))}")
    logging.info(f"üó£ Sprachen: {len(filled_json.get('languages', []))}")
    logging.info(f"‚è± Dauer: {round(time.time() - start_time, 2)} Sekunden")

if __name__ == "__main__":
    main()
