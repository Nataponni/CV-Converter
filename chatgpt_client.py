import os
import re
import json
import ast
import logging
from dotenv import load_dotenv
from openai import OpenAI
from postprocess import safe_parse_if_str, postprocess_filled_cv

# ============================================================
# üîß Initialisierung
# ============================================================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
logging.basicConfig(level=logging.INFO)

# ============================================================
# üß† Hauptfunktion zum Aufruf von GPT
# ============================================================
def ask_chatgpt(text, mode="details", base_structure=None, model="gpt-5-mini"):
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑–æ–≤–∞ GPT –¥–ª—è CV-–ø–∞—Ä—Å–∏–Ω–≥–∞.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º—ã:
    - structure: –≤—ã–≤–æ–¥–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É JSON
    - details: –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –ø–æ–ª—è –∏–∑ —Ç–µ–∫—Å—Ç–∞
    - fix: –∑–∞–ø–æ–ª–Ω—è–µ—Ç –ø—É—Å—Ç—ã–µ –ø–æ–ª—è
    """
    if mode == "structure":
        task_description = "Extract only the structural JSON skeleton of the CV with all field names but empty values."
    elif mode == "fix":
        task_description = "Repair missing or empty fields logically, keeping the schema intact."
    else:
        task_description = "Extract structured CV data from text and return strictly formatted JSON only."

    prompt = f"""
TASK: {task_description}

INSTRUCTIONS:

- Extract a complete, structured JSON strictly following the provided SCHEMA.
- Detect the candidate‚Äôs actual domain (e.g., Cloud, DevOps, BI, Data Engineering) based on tools, project content, and terminology.
- Avoid assumptions ‚Äî rely only on what's clearly stated or strongly implied in the resume.
- If a field is unknown or not present in the CV, use empty values: "" for strings, [] for lists, {{}} for objects. Do NOT guess.
- Do NOT wrap arrays or objects into strings. Always output proper JSON values.
- Always extract and include exact start and end dates for every project, job, or education entry.

=== PROJECTS ===

In the "projects_experience" field:

‚Ä¢ Extract any block that contains at least a `project_title:` ‚Äî even if duration is missing.
  ‚Üí These blocks are always valid. Extract them even if role, overview, or tech_stack are missing. Fill missing fields with empty values.
‚Ä¢ Preserve the full "duration" exactly as written (e.g., "Jul 2021 ‚Äì Present"). Do not modify, translate, or guess.
‚Ä¢ Extract only real, distinct projects. Use visual or semantic separation as an indicator (headings, date blocks, project keywords, client names, etc.).
‚Ä¢ Use concise, technical bullet points (‚â§18 words) for "responsibilities", starting with action verbs (e.g., Designed, Built, Automated, Integrated).
‚Ä¢ Do not split a single job into multiple projects unless:
  - It has distinct durations, OR
  - There is clear formatting separation.

‚Ä¢ If multiple roles or tasks are grouped under the same company and duration, treat them as one project.
‚Ä¢ Do not skip projects just because some fields are missing. If it's a valid block (with `Project:` + `title:` + `duration:`), extract it fully with empty fields where needed.
‚Ä¢ All extracted projects must follow the schema strictly.

- NEVER wrap JSON arrays or objects in strings.
  * For example, do NOT return: "projects_experience": "[{...}]"
  * Instead, return a proper JSON list: "projects_experience": [{...}]
- Do NOT return lists as strings. Fields like "projects_experience", "skills_overview", and "languages" must be actual JSON arrays ‚Äî not strings that look like lists.
- Always use double quotes for all keys and string values.
‚Ä¢ Each distinct project must become a separate JSON object in the "projects_experience" list.
‚Ä¢ Never merge or combine projects ‚Äî even if company or technologies overlap.
‚Ä¢ Use clear separators such as '=== PROJECT START ===' or 'Project:' to distinguish them.


  === SKILLS ===
- For "hard_skills" and "skills_overview":
  * Use ONLY these fixed categories:
    cloud_platforms, devops_iac, monitoring_security, programming_languages,
    containers_orchestration, ci_cd_tools, ai_ml_tools, databases,
    backend, frontend, security, data_engineering, etl_tools, bi_tools,
    analytics, infrastructure_os, other_tools

  * Do NOT merge or invent new categories like "BI / Analytics" ‚Äî always split correctly.
  * Each tool must be placed in only ONE most relevant category.
  * Tools like "Git", "Excel", "Outlook", "Power Platform" ‚Äî only use "other_tools" if nothing else fits.
  * Avoid mixing tools in one item (e.g., don't write "Python / SQL" ‚Äî create separate entries).

- For "skills_overview":
  * Include all tools used in projects or summary.
  * Estimate approximate "years_of_experience" logically (e.g., from project durations or global statements like "5+ years with Azure").
  * Output must include ‚â•10 distinct categories.
  * Each row must follow this format: {{ "category": "", "tools": [], "years_of_experience": "" }}
  ‚Ä¢ Extract any block that contains at least a `project_title:` ‚Äî even if duration is missing.
  ‚Üí If duration missing, return it as an empty string "".

  * Do not leave "tools" empty ‚Äî extract at least one tool per category if mentioned anywhere in the CV.

=== PROFILE SUMMARY ===
- Write a technical, third-person summary (80‚Äì100 words) describing actual domains, tools, and strengths.
- Align this summary strictly with real CV content ‚Äî don't invent.

=== LANGUAGES ===
- Extract only explicitly mentioned languages and their levels (e.g., "German: native", "English: C1").
- Recognize section titles such as "Languages", "Language Skills", "Sprachen", or "Sprachkenntnisse".
- Do NOT infer any languages that are not explicitly written in the CV.
- Detect levels written as ‚Äúnative‚Äù, ‚Äúfluent‚Äù, ‚ÄúC2‚Äù, ‚ÄúB1‚Äù, etc.
- If no languages are mentioned, return an empty list: []
- Output format:
  "languages": [
      {{"language": "German", "level": "C2"}},
      {{"language": "English", "level": "C1"}}
  ]

=== OUTPUT RULES ===
- Return a single valid JSON object strictly matching the SCHEMA.
- Do NOT return markdown, explanations, comments, or prose ‚Äî only JSON.
- Do NOT hallucinate tools, projects, dates, or titles.
- Do NOT change field names or structure.
- Dates must be copied exactly as in the source (no reformatting, no translation). If unclear or not present, leave empty.

SCHEMA:
{{
  "full_name": "",
  "title": "",
  "education": "",
  "languages": [{{"language": "", "level": ""}}],
  "domains": [],
  "profile_summary": "",
  "hard_skills": {{
    "programming_languages": [],
    "backend": [],
    "frontend": [],
    "databases": [],
    "data_engineering": [],
    "etl_tools": [],
    "bi_tools": [],
    "analytics": [],
    "cloud_platforms": [],
    "devops_iac": [],
    "ci_cd_tools": [],
    "containers_orchestration": [],
    "monitoring_security": [],
    "security": [],
    "ai_ml_tools": [],
    "infrastructure_os": [],
    "other_tools": []
  }},
  "projects_experience": [
    {{
      "project_title": "",
      "overview": "",
      "role": "",
      "duration": "",
      "responsibilities": [],
      "tech_stack": []
    }}
  ],
  "skills_overview": [
    {{
      "category": "",
      "tools": [],
      "years_of_experience": ""
    }}
  ],
  "website": ""
}}

TEXT:
{text}
"""

# --- Erstellen der Nachrichten
    messages = [
        {"role": "system", "content": "You are an expert CV parser."},
        {"role": "user", "content": prompt},
    ]

    if mode == "details" and base_structure:
        messages.append({
            "role": "user",
            "content": f"Use this structure strictly as your schema:\n{json.dumps(base_structure, ensure_ascii=False, indent=2)}"
        })

# --- API-Aufruf
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages
)
        raw = response.choices[0].message.content
        return {"raw_response": raw, "mode": mode, "prompt": prompt}

    except Exception as e:
        logging.error(f"‚ùå GPT error: {e}")
        return {"raw_response": "", "error": str(e)}

# ============================================================
# üîÑ Wrapper-Funktionen
# ============================================================
def extract_structure_with_gpt(text: str) -> dict:
    return ask_chatgpt(text, mode="structure")

def extract_details_with_gpt(text: str, structure: dict) -> dict:
    return ask_chatgpt(text, mode="details", base_structure=structure)

def auto_fix_missing_fields(data: dict) -> dict:
    text = json.dumps(data, ensure_ascii=False, indent=2)
    return ask_chatgpt(text, mode="fix")

def safe_json_parse(raw):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–ª–∏ –æ–±—ä–µ–∫—Ç –≤ Python-—Å–ª–æ–≤–∞—Ä—å.
    –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç JSON –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "[{...}]"),
    –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –µ–≥–æ.
    """
    if isinstance(raw, dict):
        return raw
    if isinstance(raw, list):
        return raw
    if not isinstance(raw, str):
        return {}

    try:
        # üß† –ü—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–π JSON
        return json.loads(raw)
    except json.JSONDecodeError:
        # üß© –ò–Ω–æ–≥–¥–∞ GPT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
        try:
            return json.loads(raw.replace("'", '"'))
        except Exception:
            pass
        # üß© –ò–Ω–æ–≥–¥–∞ —Å—Ç—Ä–æ–∫–∞ ‚Äî —ç—Ç–æ Python-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        try:
            return ast.literal_eval(raw)
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è safe_json_parse failed: {e}")
            return {}

def run_robust_cv_parsing(text: str, model="gpt-5-mini") -> dict:
    """
    Stabiler GPT-Aufruf im bisherigen Ein-Schritt-Modus.
    –û—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏. –ù–æ–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∏–∂–µ.
    """
    try:
        result = ask_chatgpt(text, model)
        raw_response = result.get("raw_response", "")
        parsed = safe_parse_if_str(raw_response)

        parsed["projects_experience"] = safe_parse_if_str(parsed.get("projects_experience"))
        parsed["skills_overview"] = safe_parse_if_str(parsed.get("skills_overview"))
        parsed["languages"] = safe_parse_if_str(parsed.get("languages"))

        return {
            "success": True,
            "json": parsed,
            "raw_response": raw_response,
        }
    except Exception as e:
        logging.error(f"‚ùå Parsing failed: {e}")
        return {"success": False, "json": {}, "raw_response": ""}

# ============================================================

def _call_gpt_and_parse(prompt: str, model: str = "gpt-5-mini") -> dict:
    """–û–¥–∏–Ω GPT-–≤—ã–∑–æ–≤ + –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–±–æ—Ä JSON (–æ–±—â–∏–π —Ö–µ–ª–ø–µ—Ä –¥–ª—è JSON-–æ—Ç–≤–µ—Ç–æ–≤)."""
    try:
        messages = [
            {"role": "system", "content": "You are an expert CV parser."},
            {"role": "user", "content": prompt},
        ]
        response = client.chat.completions.create(
            model=model,
            messages=messages
        )
        raw = response.choices[0].message.content or ""
        parsed = safe_parse_if_str(raw)
        return {"success": True, "json": parsed, "raw_response": raw}
    except Exception as e:
        logging.error(f"‚ùå GPT step failed: {e}")
        return {"success": False, "json": {}, "raw_response": ""}


def gpt_extract_cv_without_projects(text: str, model: str = "gpt-5-mini") -> dict:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –ø–æ–ª—è CV, –∫—Ä–æ–º–µ projects_experience (–æ–Ω –æ—Å—Ç–∞—ë—Ç—Å—è [])."""
    prompt = f"""
TASK: Extract a structured CV JSON from the text, but DO NOT extract any projects.

INSTRUCTIONS:
- Use the SCHEMA exactly as given.
- Fill all fields EXCEPT `projects_experience`.
- `projects_experience` MUST be an empty list [] in the final JSON.
- If a field is unknown, use empty values: "" for strings, [] for lists, {{}} for objects.
- Return ONLY raw JSON, no explanations.

SCHEMA:
{{
  "full_name": "",
  "title": "",
  "education": "",
  "languages": [{{"language": "", "level": ""}}],
  "domains": [],
  "profile_summary": "",
  "hard_skills": {{
    "programming_languages": [],
    "backend": [],
    "frontend": [],
    "databases": [],
    "data_engineering": [],
    "etl_tools": [],
    "bi_tools": [],
    "analytics": [],
    "cloud_platforms": [],
    "devops_iac": [],
    "ci_cd_tools": [],
    "containers_orchestration": [],
    "monitoring_security": [],
    "security": [],
    "ai_ml_tools": [],
    "infrastructure_os": [],
    "other_tools": []
  }},
  "projects_experience": [],
  "skills_overview": [{{
    "category": "",
    "tools": [],
    "years_of_experience": ""
  }}],
  "website": ""
}}

TEXT:
{text}
"""
    return _call_gpt_and_parse(prompt, model=model)


def gpt_extract_projects_text(text: str, model: str = "gpt-5-mini") -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏, —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π === PROJECT N ===."""
    prompt = f"""
TASK: Extract ONLY project sections from the following CV text.

INSTRUCTIONS:
- A project is a block describing work for a client, product or role, with responsibilities and usually a duration.
- Read the entire CV and isolate each distinct project.
- For each project, output in the following format:

=== PROJECT N ===
<raw text of the project, exactly as in the CV, with useful line breaks>

- Use consecutive numbers starting from 1.
- Keep the original ordering of projects.
- Do NOT include non-project sections (profile, skills, education, languages, etc.).
- Return ONLY plain text, no JSON, no markdown.

CV_TEXT:
{text}
"""
    try:
        messages = [
            {"role": "system", "content": "You are an expert CV parser."},
            {"role": "user", "content": prompt},
        ]
        response = client.chat.completions.create(
            model=model,
            messages=messages
        )
        raw = response.choices[0].message.content or ""
        return {"success": True, "text": raw, "raw_response": raw}
    except Exception as e:
        logging.error(f"‚ùå GPT projects-text step failed: {e}")
        return {"success": False, "text": "", "raw_response": ""}


def gpt_structurize_projects_from_text(projects_text: str, model: str = "gpt-5") -> dict:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç —Å === PROJECT N === –≤ –ø–æ–ª–µ `projects_experience` —Ü–µ–ª–µ–≤–æ–π —Å—Ö–µ–º—ã."""
    prompt = f"""
TASK: Convert the following PROJECTS text into structured JSON objects.

INPUT FORMAT:
- The text contains multiple project blocks, each starting with a delimiter line:

=== PROJECT 1 ===
<raw project text>

=== PROJECT 2 ===
<raw project text>
...

PROJECT_SCHEMA:
{{ 
  "project_title": "",
  "overview": "",
  "role": "",
  "duration": "",
  "responsibilities": [],
  "tech_stack": []
}}

INSTRUCTIONS:
- For each input project, produce one object following PROJECT_SCHEMA.
- Extract:
  - exact project_title (short, descriptive)
  - a concise overview (2‚Äì3 sentences)
  - role (e.g., "Lead BI Developer", "Data Engineer")
  - duration exactly as written in the text
  - responsibilities as bullet-style strings (start with action verbs, max 18 words)
  - tech_stack as a flat list of tools/technologies.
- If any field is missing in the text, leave it as an empty string or empty list.
- Return ONLY JSON of the form {{ "projects_experience": [PROJECT_SCHEMA, ...]}}.

PROJECTS_TEXT:
{projects_text}
"""
    return _call_gpt_and_parse(prompt, model=model)


# ============================================================
# üß™ Lokaler Testlauf
# ============================================================
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    input_path = "debug/full_prepared_text.txt"
    output_path = "debug/filled_cv_from_gpt.json"

    if not os.path.exists(input_path):
        logging.warning(f"‚ö†Ô∏è File not found: {input_path}")
        exit(1)

    with open(input_path, "r", encoding="utf-8") as f:
        input_text = f.read()

    logging.info("üì® Sending text to GPT (mode='details')...")
    structure_raw = ask_chatgpt(input_text, mode="structure")

    try:
        base_structure = json.loads(structure_raw["raw_response"])
    except Exception:
        base_structure = None

    result = ask_chatgpt(input_text, mode="details", base_structure=base_structure)

    if "raw_response" in result:
        try:
            print("\nSTEP 1Ô∏è‚É£  RAW GPT RESPONSE:\n", result.get("raw_response")[:2000])
            filled_json = safe_json_parse(result["raw_response"])
            print("\nSTEP 2Ô∏è‚É£  AFTER safe_json_parse:\n", type(filled_json.get("projects_experience")), len(str(filled_json.get("projects_experience"))))

            with open("debug/full_prepared_text.txt", "r", encoding="utf-8") as f:
                raw_text = f.read()

            filled_json["projects_experience"] = safe_parse_if_str(filled_json.get("projects_experience"))
            print("\nSTEP 3Ô∏è‚É£  AFTER safe_parse_if_str:\n", type(filled_json.get("projects_experience")), len(filled_json.get("projects_experience", [])))

            filled_json["skills_overview"] = safe_parse_if_str(filled_json.get("skills_overview"))

            filled_json = postprocess_filled_cv(filled_json, raw_text)
            print("\nSTEP 3Ô∏è‚É£  AFTER safe_parse_if_str:\n", type(filled_json.get("projects_experience")), len(filled_json.get("projects_experience", [])))
            
            with open(output_path, "w", encoding="utf-8") as out_f:
                json.dump(filled_json, out_f, indent=2, ensure_ascii=False)

            logging.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

        except json.JSONDecodeError as e:
            logging.error("‚ùå JSON parsing error:")
            logging.error(e)
            logging.warning("‚ö†Ô∏è GPT response:")
            print(result["raw_response"])
    else:
        logging.error("‚ùå GPT did not return a valid response.")