import os
import re
import fitz  # PyMuPDF
from langdetect import detect, DetectorFactory
from chatgpt_client import ask_chatgpt

DetectorFactory.seed = 0  # F√ºr stabile Sprachenerkennung

# ============================================================
# 1Ô∏è‚É£ PDF ‚Üí Text Extraktion (seitenweise)
# ============================================================
def extract_text_by_page(pdf_path: str) -> list[str]:
    """Extrahiert den Text jeder Seite aus dem PDF."""
    doc = fitz.open(pdf_path)
    pages_text = []

    for page in doc:
        blocks = page.get_text("blocks") or page.get_text("text")
        if isinstance(blocks, list):
            text = "\n".join([b[4] for b in blocks if b[4].strip()])
        else:
            text = blocks

        text = re.sub(r"[ \t]+", " ", text)
        text = re.sub(r"\n{2,}", "\n", text)
        pages_text.append(text.strip())

    doc.close()
    return pages_text


# ============================================================
# 2Ô∏è‚É£ Datumserkennung (inkl. Deutschformate)
# ============================================================
def tag_dates(text: str) -> str:
    """Markiert Zeitr√§ume und einzelne Datumsangaben mit [DATE]...[/DATE]."""
    patterns = [
        r"\b(0?[1-9]|1[0-2])\.(\d{2})\s*[-‚Äì]\s*(0?[1-9]|1[0-2])\.(\d{2})\b",
        r"\b(0?[1-9]|1[0-2])\.(\d{2})\s*[-‚Äì]\s*(Jetzt|Derzeit|Heute|Present|Now|Aktuell)\b",
        r"\b(0?[1-9]|1[0-2])\.\d{2}\b\s*[-‚Äì]\s*$",
        r"\b(0?[1-9]|1[0-2])\/(\d{4})\s*[-‚Äì]\s*(0?[1-9]|1[0-2])\/(\d{4})\b",
        r"\b(0?[1-9]|1[0-2])\/(\d{4})\s*[-‚Äì]\s*(Jetzt|Derzeit|Heute|Present|Now|Aktuell)\b",
        r"(?i)\b(seit|since)\s+(0?[1-9]|1[0-2])[./](\d{2,4})\b",
        r"\b(20\d{2}|19\d{2})\s*[-‚Äì]\s*(20\d{2}|Present|Now|Heute|Jetzt|Aktuell)\b",
        r"(?:(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*)\s+\d{4}\s*[-‚Äì]\s*(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)?[a-z]*\s*\d{4}",
        r"\b(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d{4}\s*[-‚Äì]\s*(Present|Now|\d{4})",
        r"\b(0?[1-9]|1[0-2])[./-](\d{2,4})\s*[-‚Äì]\s*(0?[1-9]|1[0-2])[./-](\d{2,4})\b",
    ]

    for pattern in patterns:
        text = re.sub(pattern, lambda m: f"[DATE]{m.group(0)}[/DATE]", text, flags=re.IGNORECASE)

    text = re.sub(r"\bn(Jetzt|Heute)\b", r"\1", text, flags=re.IGNORECASE)
    text = re.sub(r"\b(Jetzt|Derzeit|Aktuell|Heute)\b", "Present", text, flags=re.IGNORECASE)
    return text


def merge_floating_dates(text: str) -> str:
    """F√ºgt Datumsteile zusammen, die durch Zeilenumbr√ºche getrennt wurden."""
    text = re.sub(r'(?<!\d)(\d{2}\.\d{2})\s*\n\s*(\d{2}\.\d{2})(?!\d)', r'\1 ‚Äì \2', text)
    text = re.sub(r'(?<!\d)(\d{2}/\d{4})\s*\n\s*(\d{2}/\d{4})(?!\d)', r'\1 ‚Äì \2', text)
    return text

# ============================================================
# 2Ô∏è‚É£.5Ô∏è‚É£ Projekte mit Datumszeilen verbinden
# ============================================================
def merge_project_blocks(text: str) -> str:
    """
    –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Ä–æ–ª–µ–π –∏ –¥–∞—Ç –≤ –æ–¥–∏–Ω –±–ª–æ–∫:
    'Lead BI Developer - Inpro Analytics GmbH' + '01.23 ‚Äì Jetzt'
    ‚Üí 'Lead BI Developer - Inpro Analytics GmbH 01.23 ‚Äì Jetzt'
    """
    # –°–æ–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç—ã, —Å—Ç–æ—è—â–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ, —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π
    text = re.sub(r'(\n)(\d{1,2}[./]\d{2}\s*[‚Äì-]\s*(Jetzt|Heute|Present|\d{1,2}[./]\d{2}))', r' \2', text)
    text = re.sub(r'(\n)(\d{4}\s*[‚Äì-]\s*(Present|\d{4}))', r' \2', text)

    # –í–º–µ—Å—Ç–æ lookbehind –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å—Å—ã–ª–∫–æ–π
    text = re.sub(
        r'(\b(?:Developer|Engineer|Architect|Consultant|Manager|Lead|Analyst|Director|Specialist))\s*\n\s*(\d{1,2}[./]\d{2}\s*[‚Äì-]\s*(?:Jetzt|Heute|Present|\d{1,2}[./]\d{2}))',
        r'\1 \2',
        text,
        flags=re.IGNORECASE,
    )

    return text


# ============================================================
# 3Ô∏è‚É£ Sektionen markieren & strukturieren
# ============================================================
def clean_text(text: str) -> str:
    """Erkennt und markiert Hauptsektionen wie [PROJECTS], [SKILLS], usw."""
    text = re.sub(r"\[\d+\]|\(\d+\)", "", text)
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r"\s{2,}", " ", text)

    section_markers = {
        r"(?i)(Domains?|Industries):?": "[DOMAINS]",
        r"(?i)(Languages?|Sprachen|Sprachkenntnisse):?": "[LANGUAGES]",
        r"(?i)(Education|Studium|Ausbildung|Academic Background):?": "[EDUCATION]",
        r"(?i)(Profile|Summary|√úber mich|Professional Summary):": "[PROFILE_SUMMARY]",
        r"(?i)(Projects?|Experience|Berufserfahrung|Work Experience):?": "[PROJECTS]",
        r"(?i)(Skills|Technologies|Kompetenzen|Tools):?": "[SKILLS]",
    }

    for pattern, marker in section_markers.items():
        text = re.sub(pattern, f"\n{marker}\n\\1", text)

    tags = ["DOMAINS", "SKILLS", "LANGUAGES", "EDUCATION", "PROJECTS", "PROFILE_SUMMARY"]
    for i, tag in enumerate(tags):
        next_tags = tags[i + 1:]
        next_pattern = "|".join(f"\\[{t}\\]" for t in next_tags) if next_tags else "$"

        # –Ø–≤–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ–∫—Ü–∏—é, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–ª–∞ –≤—Å—ë –¥–æ –∫–æ–Ω—Ü–∞
        text = re.sub(
            rf"(\[{tag}\])(.*?)(?=\n({next_pattern})|\Z)",
            rf"\1\2[/{tag}]\n",
            text,
            flags=re.DOTALL,
        )
    text = re.sub(r"\]\s*\[", "]\n\n[", text)

    # Zus√§tzliche GPT-Hilfen
    text = re.sub(
        r"\[EDUCATION\]",
        "[EDUCATION]\nKontext: Dies sind akademische Qualifikationen, keine Berufserfahrung.\n",
        text,
    )
    text = re.sub(
        r"\[PROJECTS\]",
        "[PROJECTS]\nKontext: Dies sind berufliche Projekte, oft im Rahmen von T√§tigkeiten.\n",
        text,
    )

    return text.strip()


def normalize_structure(text: str) -> str:
    """
    F√ºgt semantische Tags f√ºr schwach strukturierte Lebensl√§ufe hinzu.
    Zum Beispiel: "worked on several projects..." ‚Üí [PROJECTS]
    """
    replacements = {
        r"(?i)\b(profile|about me|summary)\b": "[PROFILE_SUMMARY]",
        r"(?i)\b(experience|employment|projects?|career)\b": "[PROJECTS]",
        r"(?i)\b(education|studies|academic background)\b": "[EDUCATION]",
        r"(?i)\b(skills|technologies|competencies|tools)\b": "[SKILLS]",
        r"(?i)\b(languages|sprachkenntnisse)\b": "[LANGUAGES]",
    }

    for pattern, tag in replacements.items():
        text = re.sub(pattern, tag, text)

    return text

# ============================================================
# 4Ô∏è‚É£ Hauptfunktion zur Vorbereitung des CV-Texts
# ============================================================
def prepare_cv_text(pdf_path: str, cache_dir="data_output") -> tuple[str, str]:
    """
    Extrahiert Text aus dem PDF, √ºbersetzt ihn bei Bedarf, markiert Datumsangaben,
    bereinigt die Struktur und bereitet den Text f√ºr GPT vor. Gibt zur√ºck:
    (den normalisierten Text, den Originaltext).
    """
    import os
    from langdetect import detect

    os.makedirs(cache_dir, exist_ok=True)

    pages = extract_text_by_page(pdf_path)
    raw_text = "\n\n".join(pages)

    try:
        detected_lang = detect(raw_text)
    except Exception:
        detected_lang = "en"

    if detected_lang != "en":
        translation_prompt = f"""
Translate this CV text from German to English word-by-word, preserving the exact line structure.
Do NOT split or merge projects. Do NOT add numbering or new sections.
Preserve ALL original formatting and project boundaries.
TEXT:
{raw_text[:15000]}
"""
        result = ask_chatgpt(translation_prompt)

        if isinstance(result, dict) and "raw_response" in result:
            raw_text = result["raw_response"]
        elif isinstance(result, str):
            raw_text = result

        raw_text = re.sub(r"(?i)\b(sprachen|sprachkenntnisse)\b", "Languages", raw_text)
        raw_text = re.sub(r"(?i)\b(ausbildung|bildung)\b", "Education", raw_text)
        raw_text = re.sub(r"(?i)\b(berufserfahrung|erfahrung|projekte|projects?)\b", "Experience", raw_text)
        raw_text = re.sub(r"(?i)\b(kenntnisse|skills|kompetenzen|technologien|tools)\b", "Skills", raw_text)

    tagged_text = tag_dates(raw_text)
    tagged_text = merge_project_blocks(tagged_text)

    tagged_text = re.sub(r"[^\w\s\.\-/‚Äì‚Äî:,]", " ", tagged_text) 
    tagged_text = re.sub(r"\s{3,}", "\n", tagged_text)
    tagged_text = re.sub(r"[ \t]+", " ", tagged_text)
    tagged_text = re.sub(r"\n{2,}", "\n", tagged_text)

    cleaned_text = clean_text(tagged_text)

    # normalized_text = normalize_structure(cleaned_text)
    normalized_text = cleaned_text
    
    final_text = (
        "[CV_START]\n"
        "The following is a professional CV. Detect all project durations accurately.\n"
        + normalized_text +
        "\n[CV_END]"
    )
    with open(os.path.join(cache_dir, "prepared_text.txt"), "w", encoding="utf-8") as f:
        f.write(final_text)

    # –õ—ë–≥–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –¥–ª—è raw_text
    raw_text = re.sub(r"[^\w\s\.\-/‚Äì‚Äî:,]", " ", raw_text)
    raw_text = re.sub(r"\s{3,}", "\n", raw_text)
    raw_text = re.sub(r"[ \t]+", " ", raw_text)
    raw_text = re.sub(r"\n{2,}", "\n", raw_text)

    return final_text, raw_text


# ============================================================
# üß™ Lokaler Testlauf
# ============================================================
if __name__ == "__main__":
    path = "data_input/CV Manuel Wolfsgruber.pdf"
    os.makedirs("debug", exist_ok=True)

    prepared, raw = prepare_cv_text(path)

    with open("debug/full_prepared_text.txt", "w", encoding="utf-8") as f:
        f.write(prepared)
    with open("debug/raw_extracted_text.txt", "w", encoding="utf-8") as f:
        f.write(raw)

    print("\n‚úÖ Alles fertig!")
    print("üìÑ full_prepared_text.txt ‚Äî vorbereiteter Text")
    print("üóí raw_extracted_text.txt ‚Äî Rohtext aus dem PDF")
